{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "[pm] = qml.data.load('other', name='plus-minus')\n",
        "\n",
        "X_train = pm.img_train  # shape (1000,16,16)\n",
        "X_test = pm.img_test  # shape (200,16,16)\n",
        "Y_train = pm.labels_train  # shape (1000,)\n",
        "Y_test = pm.labels_test  # shape (200,)\n",
        "\n",
        "x_vis = [\n",
        "    (X_train[Y_train == 0])[0],\n",
        "    (X_train[Y_train == 1])[0],\n",
        "    (X_train[Y_train == 2])[0],\n",
        "    (X_train[Y_train == 3])[0],\n",
        "]\n",
        "y_vis = [0, 1, 2, 3]\n",
        "\n",
        "\n",
        "def visualize_data(x, y, pred=None):\n",
        "    n_img = len(x)\n",
        "    labels_list = [\"\\u2212\", \"\\u002b\", \"\\ua714\", \"\\u02e7\"]\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
        "    for i in range(n_img):\n",
        "        axes[i].imshow(x[i], cmap=\"gray\")\n",
        "        if pred is None:\n",
        "            axes[i].set_title(\"Label: {}\".format(labels_list[y[i]]))\n",
        "        else:\n",
        "            axes[i].set_title(\"Label: {}, Pred: {}\".format(labels_list[y[i]], labels_list[pred[i]]))\n",
        "    plt.tight_layout(w_pad=2)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "visualize_data(x_vis, y_vis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#### Hyperparameters ####\n",
        "input_dim = 256\n",
        "num_classes = 4\n",
        "num_layers = 32\n",
        "num_qubits = 8\n",
        "num_reup = 3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "class QML_classifier(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Class for creating a quantum machine learning (classification) model based on the StronglyEntanglingLayers template.\n",
        "\n",
        "    Args:\n",
        "        input_dim: the dimension of the input samples\n",
        "        output_dim: the dimension of the output, i.e. the numbers of classes \n",
        "        num_qubits: the number of qubits in the circuit\n",
        "        num_layers: the number of layers within the StronglyEntanglingLayers template\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, num_qubits, num_layers):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1337)  # fixed seed for reproducibility\n",
        "        self.num_qubits = num_qubits\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.device = qml.device(\"lightning.qubit\", wires=self.num_qubits)\n",
        "        self.weights_shape = qml.StronglyEntanglingLayers.shape(\n",
        "            n_layers=self.num_layers, n_wires=self.num_qubits\n",
        "        )\n",
        "\n",
        "        @qml.qnode(self.device)\n",
        "        def circuit(inputs, weights, bias):\n",
        "            inputs = torch.reshape(inputs, self.weights_shape)\n",
        "            qml.StronglyEntanglingLayers(\n",
        "                weights=weights * inputs + bias, wires=range(self.num_qubits)\n",
        "            )\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(self.output_dim)]\n",
        "\n",
        "        param_shapes = {\"weights\": self.weights_shape, \"bias\": self.weights_shape}\n",
        "        init_vals = {\n",
        "            \"weights\": 0.1 * torch.rand(self.weights_shape),\n",
        "            \"bias\": 0.1 * torch.rand(self.weights_shape),\n",
        "        }\n",
        "\n",
        "        # initialize the quantum circuit\n",
        "        self.qcircuit = qml.qnn.TorchLayer(\n",
        "            qnode=circuit, weight_shapes=param_shapes, init_method=init_vals\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs_stack = torch.hstack([x] * num_reup)\n",
        "        return self.qcircuit(inputs_stack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 4\n",
        "batch_size = 20\n",
        "\n",
        "feats_train = torch.from_numpy(X_train[:200]).reshape(200, -1).to(device)\n",
        "feats_test = torch.from_numpy(X_test[:50]).reshape(50, -1).to(device)\n",
        "labels_train = torch.from_numpy(Y_train[:200]).to(device)\n",
        "labels_test = torch.from_numpy(Y_test[:50]).to(device)\n",
        "num_train = feats_train.shape[0]\n",
        "\n",
        "qml_model = QML_classifier(input_dim, num_classes, num_qubits, num_layers)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(qml_model.parameters(), lr=learning_rate)\n",
        "num_batches = feats_train.shape[0] // batch_size\n",
        "\n",
        "\n",
        "def accuracy(labels, predictions):\n",
        "    acc = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        if torch.argmax(p) == l:\n",
        "            acc += 1\n",
        "    acc = acc / len(labels)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def gen_batches(num_samples, num_batches):\n",
        "    assert num_samples % num_batches == 0\n",
        "    perm_ind = torch.reshape(torch.randperm(num_samples), (num_batches, -1))\n",
        "    return perm_ind\n",
        "\n",
        "\n",
        "def print_acc(epoch, max_ep=4):\n",
        "    predictions_train = [qml_model(f) for f in feats_train[:50]]\n",
        "    predictions_test = [qml_model(f) for f in feats_test]\n",
        "    cost_approx_train = loss(torch.stack(predictions_train), labels_train[:50])\n",
        "    cost_approx_test = loss(torch.stack(predictions_test), labels_test)\n",
        "    acc_approx_train = accuracy(labels_train[:50], predictions_train)\n",
        "    acc_approx_test = accuracy(labels_test, predictions_test)\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{max_ep} | Approx Cost (train): {cost_approx_train:0.7f} | Cost (val): {cost_approx_test:0.7f} |\"\n",
        "        f\" Approx Acc train: {acc_approx_train:0.7f} | Acc val: {acc_approx_test:0.7f}\"\n",
        "    )\n",
        "\n",
        "\n",
        "print(\n",
        "    f\"Starting training loop for quantum variational classifier ({num_qubits} qubits, {num_layers} layers)...\"\n",
        ")\n",
        "\n",
        "for ep in range(0, epochs):\n",
        "    batch_ind = gen_batches(num_train, num_batches)\n",
        "    print_acc(epoch=ep)\n",
        "\n",
        "    for it in range(num_batches):\n",
        "        optimizer.zero_grad()\n",
        "        feats_train_batch = feats_train[batch_ind[it]]\n",
        "        labels_train_batch = labels_train[batch_ind[it]]\n",
        "\n",
        "        outputs = [qml_model(f) for f in feats_train_batch]\n",
        "        batch_loss = loss(torch.stack(outputs), labels_train_batch)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print_acc(epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# show accuracy\n",
        "x_vis_torch = torch.from_numpy(np.array(x_vis).reshape(4, -1))\n",
        "y_vis_torch = torch.from_numpy(np.array(y_vis))\n",
        "benign_preds = [qml_model(f) for f in x_vis_torch]\n",
        "\n",
        "benign_class_output = [torch.argmax(p) for p in benign_preds]\n",
        "visualize_data(x_vis, y_vis, benign_class_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def PGD(model, feats, labels, epsilon=0.1, alpha=0.01, num_iter=10):\n",
        "\n",
        "    delta = torch.zeros_like(feats, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "        feats_adv = feats + delta\n",
        "        outputs = [model(f) for f in feats_adv]\n",
        "\n",
        "        l = loss(torch.stack(outputs), labels)\n",
        "        l.backward()\n",
        "\n",
        "        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "perturbations = PGD(model=qml_model, feats=x_vis_torch, labels=y_vis_torch, epsilon=0.1)\n",
        "perturbed_x = x_vis_torch + perturbations\n",
        "\n",
        "adversarial_preds = [qml_model(f) for f in perturbed_x]\n",
        "adversarial_class_output = [torch.argmax(p) for p in adversarial_preds]\n",
        "\n",
        "visualize_data(perturbed_x.reshape(-1, 16, 16), y_vis, adversarial_class_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adv_dataset = (\n",
        "    PGD(model=qml_model, feats=feats_train[:20], labels=labels_train[:20], epsilon=0.1)\n",
        "    + feats_train[:20]\n",
        ")\n",
        "\n",
        "feats_retrain = torch.cat((feats_train, adv_dataset))\n",
        "labels_retrain = torch.cat((labels_train, labels_train[:20]))\n",
        "epochs_retraining = 2\n",
        "\n",
        "for ep in range(0, epochs_retraining):\n",
        "    batch_ind = gen_batches(num_train, num_batches)\n",
        "    print_acc(epoch=ep, max_ep=2)\n",
        "\n",
        "    for it in range(num_batches):\n",
        "        optimizer.zero_grad()\n",
        "        feats_train_batch = feats_retrain[batch_ind[it]]\n",
        "        labels_train_batch = labels_retrain[batch_ind[it]]\n",
        "\n",
        "        outputs = [qml_model(f) for f in feats_train_batch]\n",
        "        batch_loss = loss(torch.stack(outputs), labels_train_batch)\n",
        "            \n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print_acc(epochs_retraining, max_ep=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adversarial_preds = [qml_model(f) for f in perturbed_x]\n",
        "adversarial_class_output = [torch.argmax(p) for p in adversarial_preds]\n",
        "\n",
        "visualize_data(perturbed_x.reshape(-1, 16, 16), y_vis, adversarial_class_output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
